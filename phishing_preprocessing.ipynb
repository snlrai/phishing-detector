{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMek5nBEzpemZ+BrnBSoLj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArTAouer0C4A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('phishing_email.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Make sure the CSV file is in the same directory as your script.\")\n",
        "    exit()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=['label'], inplace=True)"
      ],
      "metadata": {
        "id": "9xqLMK_4GN72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hbBrIWw1grl",
        "outputId": "695c1675-dca7-41ed-b022-705a2de4b349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       text_combined  label\n",
            "0  hpl nom may 25 2001 see attached file hplno 52...      0\n",
            "1  nom actual vols 24 th forwarded sabrae zajac h...      0\n",
            "2  enron actuals march 30 april 1 201 estimated a...      0\n",
            "3  hpl nom may 30 2001 see attached file hplno 53...      0\n",
            "4  hpl nom june 1 2001 see attached file hplno 60...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5Kzvpbi1kHr",
        "outputId": "5d7e2fc9-fe0a-43eb-e54a-e201ff92a609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 82486 entries, 0 to 82485\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   text_combined  82486 non-null  object\n",
            " 1   label          82486 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.3+ MB\n",
            "\n",
            "========================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "SA3Q5EhY1ohL",
        "outputId": "fec99aab-bcb7-49f7-d175-4e6847696c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    42891\n",
              "0    39595\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39595</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text_combined']\n",
        "y = df['label']"
      ],
      "metadata": {
        "id": "ky_6Ja0W1x7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "9WzoG6_y2W_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Data successfully loaded and split.\")\n",
        "print(f\"Training set size: {len(X_train)} emails\")\n",
        "print(f\"Testing set size: {len(X_test)} emails\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SX_Z3Yc2aJZ",
        "outputId": "96afbba3-2683-400a-90e2-a9e016364296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully loaded and split.\n",
            "Training set size: 65988 emails\n",
            "Testing set size: 16498 emails\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "suspicious_keywords = [\n",
        "    \"verify\", \"password\", \"urgent\", \"account\", \"login\", \"bank\",\n",
        "    \"limited\", \"security\", \"update\", \"confirm\"\n",
        "]\n",
        "\n",
        "def engineer_features(email_text):\n",
        "\n",
        "\n",
        "    if not isinstance(email_text, str):\n",
        "        email_text = \"\"\n",
        "\n",
        "    features = {}\n",
        "\n",
        "\n",
        "    features['word_count'] = len(email_text.split())\n",
        "\n",
        "\n",
        "    features['char_count'] = len(email_text)\n",
        "\n",
        "\n",
        "    features['keyword_count'] = sum(1 for keyword in suspicious_keywords if keyword in email_text.lower())\n",
        "\n",
        "\n",
        "    features['link_count'] = len(re.findall(r'http[s]?://', email_text))\n",
        "\n",
        "\n",
        "    uppercase_chars = sum(1 for char in email_text if char.isupper())\n",
        "    features['uppercase_ratio'] = uppercase_chars / features['char_count'] if features['char_count'] > 0 else 0\n",
        "\n",
        "\n",
        "    features['punctuation_count'] = sum(1 for char in email_text if char in string.punctuation)\n",
        "\n",
        "    features['number_count'] = sum(1 for char in email_text if char.isdigit())\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "sample_email_text = X_train.iloc[0]\n",
        "extracted_features = engineer_features(sample_email_text)\n",
        "\n",
        "print(\"--- Features extracted from a sample email ---\")\n",
        "print(extracted_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHAm1fiI2gTK",
        "outputId": "b47c93ef-d913-476f-b2e5-bc8bc947293a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Features extracted from a sample email ---\n",
            "{'word_count': 42, 'char_count': 286, 'keyword_count': 0, 'link_count': 0, 'uppercase_ratio': 0.0, 'punctuation_count': 0, 'number_count': 28}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Applying feature engineering to the training set...\")\n",
        "X_train_features_list = X_train.apply(engineer_features)\n",
        "X_train_features = pd.DataFrame(X_train_features_list.tolist(), index=X_train.index)\n",
        "\n",
        "print(\"Applying feature engineering to the testing set...\")\n",
        "X_test_features_list = X_test.apply(engineer_features)\n",
        "X_test_features = pd.DataFrame(X_test_features_list.tolist(), index=X_test.index)\n",
        "\n",
        "print(\"\\n--- First 5 rows of your new engineered training features ---\")\n",
        "print(X_train_features.head())\n",
        "\n",
        "print(\"\\nFeature engineering complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0W6fWo43Xbh",
        "outputId": "987e568e-8606-4fde-b087-3cd01f9958ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying feature engineering to the training set...\n",
            "Applying feature engineering to the testing set...\n",
            "\n",
            "--- First 5 rows of your new engineered training features ---\n",
            "       word_count  char_count  keyword_count  link_count  uppercase_ratio  \\\n",
            "36471          42         286              0           0              0.0   \n",
            "7743          400        2504              1           0              0.0   \n",
            "43256          21         168              0           0              0.0   \n",
            "52280          16         120              0           0              0.0   \n",
            "22663         490        3522              0           0              0.0   \n",
            "\n",
            "       punctuation_count  number_count  \n",
            "36471                  0            28  \n",
            "7743                  13            99  \n",
            "43256                  0            16  \n",
            "52280                  0            16  \n",
            "22663                  0            22  \n",
            "\n",
            "Feature engineering complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from scipy.sparse import hstack\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "print(\"Vectorizing email text with TF-IDF...\")\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=2000)\n",
        "\n",
        "\n",
        "X_train_text = vectorizer.fit_transform(X_train)\n",
        "X_test_text = vectorizer.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Combining text features with engineered features...\")\n",
        "X_train_final = hstack([X_train_text, X_train_features.values])\n",
        "X_test_final = hstack([X_test_text, X_test_features.values])\n",
        "\n",
        "print(\"\\n--- Training Baseline Model: Logistic Regression ---\")\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train_final, y_train)\n",
        "\n",
        "lr_predictions = lr_model.predict(X_test_final)\n",
        "\n",
        "#Define the parameters you want to search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "#Set up the Grid Search with Cross-Validation (cv=3)\n",
        "# split the data into 3 folds\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "print(\"--- Starting Hyperparameter Tuning with GridSearchCV ---\")\n",
        "#Fit the grid search to the data\n",
        "grid_search.fit(X_train_final, y_train)\n",
        "\n",
        "print(f\"\\nBest parameters found: {grid_search.best_params_}\")\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "\n",
        "rf_predictions = best_rf_model.predict(X_test_final)\n",
        "\n",
        "print(\"\\n--- Evaluation: Tuned Random Forest ---\")\n",
        "print(classification_report(y_test, rf_predictions, target_names=['Safe Email', 'Phishing']))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_predictions))\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "print(\"--- Top 15 Most Important Features for Random Forest Model ---\")\n",
        "text_feature_names = vectorizer.get_feature_names_out()\n",
        "engineered_feature_names = X_train_features.columns.tolist()\n",
        "all_feature_names = np.concatenate([text_feature_names, engineered_feature_names])\n",
        "\n",
        "\n",
        "importances = best_rf_model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "\n",
        "for i in range(15):\n",
        "    print(f\"{i+1}. Feature: {all_feature_names[indices[i]]} (Importance: {importances[indices[i]]:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyVefFvv3tXJ",
        "outputId": "0d91c4be-6e53-4558-b113-2a6faeb7fc1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorizing email text with TF-IDF...\n",
            "Combining text features with engineered features...\n",
            "\n",
            "--- Training Baseline Model: Logistic Regression ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "\n",
            "--- Starting Hyperparameter Tuning with GridSearchCV ---\n",
            "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
            "\n",
            "Best parameters found: {'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 100}\n",
            "\n",
            "--- Evaluation: Tuned Random Forest ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Safe Email       0.99      0.98      0.98      7935\n",
            "    Phishing       0.99      0.99      0.99      8563\n",
            "\n",
            "    accuracy                           0.99     16498\n",
            "   macro avg       0.99      0.99      0.99     16498\n",
            "weighted avg       0.99      0.99      0.99     16498\n",
            "\n",
            "Confusion Matrix:\n",
            "[[7808  127]\n",
            " [ 114 8449]]\n",
            "\n",
            "========================================\n",
            "\n",
            "--- Top 15 Most Important Features for Random Forest Model ---\n",
            "1. Feature: wrote (Importance: 0.0300)\n",
            "2. Feature: aug (Importance: 0.0262)\n",
            "3. Feature: number_count (Importance: 0.0260)\n",
            "4. Feature: 2008 (Importance: 0.0237)\n",
            "5. Feature: enron (Importance: 0.0229)\n",
            "6. Feature: char_count (Importance: 0.0203)\n",
            "7. Feature: word_count (Importance: 0.0140)\n",
            "8. Feature: thanks (Importance: 0.0132)\n",
            "9. Feature: punctuation_count (Importance: 0.0122)\n",
            "10. Feature: pm (Importance: 0.0115)\n",
            "11. Feature: list (Importance: 0.0106)\n",
            "12. Feature: money (Importance: 0.0106)\n",
            "13. Feature: _______________________________________________ (Importance: 0.0099)\n",
            "14. Feature: subject (Importance: 0.0081)\n",
            "15. Feature: click (Importance: 0.0081)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(best_rf_model, 'model.pkl')\n",
        "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
        "print(\"Model and vectorizer saved as model.pkl and vectorizer.pkl\")\n"
      ],
      "metadata": {
        "id": "HYcp8jw_4V-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f87160-aff2-42ec-d78f-18a16043bac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and vectorizer saved as model.pkl and vectorizer.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "peeu4agCE7WL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}